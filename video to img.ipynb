{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mtcnn import MTCNN\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize MTCNN face detector\n",
    "detector = MTCNN()\n",
    "\n",
    "# Paths and setup\n",
    "video_folder = '../input/deepfake-detection-challenge/train_sample_videos/'\n",
    "metadata_path = '../input/deepfake-detection-challenge/train_sample_videos/metadata.json'\n",
    "output_real_folder = './extracted_faces/real/'\n",
    "output_fake_folder = './extracted_faces/fake/'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(output_real_folder, exist_ok=True)\n",
    "os.makedirs(output_fake_folder, exist_ok=True)\n",
    "\n",
    "# Load metadata\n",
    "train_sample_metadata = pd.read_json(metadata_path).T\n",
    "\n",
    "# Function to detect and save faces from video frames\n",
    "def extract_faces(video_path, output_folder, label, video_name):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        faces = detector.detect_faces(frame_rgb)\n",
    "        \n",
    "        for i, face in enumerate(faces):\n",
    "            x, y, width, height = face['box']\n",
    "            face_img = frame_rgb[y:y+height, x:x+width]\n",
    "            face_img = cv2.resize(face_img, (224, 224))  # Resize face to 224x224\n",
    "            \n",
    "            # Save the face image\n",
    "            face_filename = f\"{label}_{video_name}_{frame_count}_{i}.jpg\"\n",
    "            face_filepath = os.path.join(output_folder, face_filename)\n",
    "            cv2.imwrite(face_filepath, cv2.cvtColor(face_img, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        frame_count += 1\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "# Extract faces from videos\n",
    "for video_name, row in tqdm(train_sample_metadata.iterrows(), total=train_sample_metadata.shape[0]):\n",
    "    video_path = os.path.join(video_folder, video_name)\n",
    "    label = row['label']\n",
    "    output_folder = output_real_folder if label == 'REAL' else output_fake_folder\n",
    "    extract_faces(video_path, output_folder, label, video_name)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
